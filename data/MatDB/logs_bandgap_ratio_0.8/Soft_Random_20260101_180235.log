--- Baseline MLP Pipeline (Method: Soft Random) ---
Loading data from:
  Theory: ../bandgap/theory_features_clean.csv
  Exp: ../bandgap/exp_features_clean.csv
Full Source Data: 7908 | Target Train: 632
Initializing ResNet Baseline (Dim=128)...

=== Stage 0: Coreset Selection [Soft Random] ===
   Target Ratio: 80.0%

[Sampler] Running Soft Random | Target: 6326/7908 (80.0%)
Scanning Source (Soft Random):   0%|          | 0/8 [00:00<?, ?it/s]Scanning Source (Soft Random):  12%|█▎        | 1/8 [00:00<00:00,  9.38it/s]                                                                            -> Selected 6326 samples.

=== PHASE 1: Source Pre-training ===
[P1] Ep 20: Loss 0.8495
[P1] Ep 40: Loss 0.6853
[P1] Ep 60: Loss 0.5956
[P1] Ep 80: Loss 0.5390
[P1] Ep 100: Loss 0.4976
[P1] Ep 120: Loss 0.4662
[P1] Ep 140: Loss 0.4306
[P1] Ep 160: Loss 0.4008
[P1] Ep 180: Loss 0.3695
[P1] Ep 200: Loss 0.3554
[P1] Ep 220: Loss 0.3262
[P1] Ep 240: Loss 0.3128
[P1] Ep 260: Loss 0.3069
[P1] Ep 280: Loss 0.2894
[P1] Ep 300: Loss 0.2719
[P1] Ep 320: Loss 0.2625
[P1] Ep 340: Loss 0.2571
[P1] Ep 360: Loss 0.2377
[P1] Ep 380: Loss 0.2329
[P1] Ep 400: Loss 0.2250
[P1] Ep 420: Loss 0.2050
[P1] Ep 440: Loss 0.2069
[P1] Ep 460: Loss 0.1955
[P1] Ep 480: Loss 0.1971
[P1] Ep 500: Loss 0.1884
[P1] Ep 520: Loss 0.1812
[P1] Ep 540: Loss 0.1799
[P1] Ep 560: Loss 0.1723
[P1] Ep 580: Loss 0.1678
[P1] Ep 600: Loss 0.1609
[P1] Ep 620: Loss 0.1594
[P1] Ep 640: Loss 0.1552
[P1] Ep 660: Loss 0.1466
[P1] Ep 680: Loss 0.1500
[P1] Ep 700: Loss 0.1423
[P1] Ep 720: Loss 0.1423
[P1] Ep 740: Loss 0.1354
[P1] Ep 760: Loss 0.1349
[P1] Ep 780: Loss 0.1295
[P1] Ep 800: Loss 0.1295
[P1] Ep 820: Loss 0.1244
[P1] Ep 840: Loss 0.1170
[P1] Ep 860: Loss 0.1192
[P1] Ep 880: Loss 0.1192
[P1] Ep 900: Loss 0.1190
[P1] Ep 920: Loss 0.1096
[P1] Ep 940: Loss 0.1116
[P1] Ep 960: Loss 0.1121
[P1] Ep 980: Loss 0.1070
[P1] Ep 1000: Loss 0.1041

=== PHASE 2.1: Head Alignment ===
[P2.1] Ep 50 MAE 0.8368
[P2.1] Ep 100 MAE 0.8517

=== PHASE 2.2: Full Fine-tuning ===
[P2.2] Ep 20 MAE 0.7245
[P2.2] Ep 40 MAE 0.7177
[P2.2] Ep 60 MAE 0.7109
[P2.2] Ep 80 MAE 0.7058
[P2.2] Ep 100 MAE 0.7029
[P2.2] Ep 120 MAE 0.6902
[P2.2] Ep 140 MAE 0.6949
[P2.2] Ep 160 MAE 0.6883
[P2.2] Ep 180 MAE 0.6960
[P2.2] Ep 200 MAE 0.6827
[P2.2] Ep 220 MAE 0.6841
[P2.2] Ep 240 MAE 0.6909
[P2.2] Ep 260 MAE 0.6953
[P2.2] Ep 280 MAE 0.6822
[P2.2] Ep 300 MAE 0.6743
[P2.2] Ep 320 MAE 0.6828
[P2.2] Ep 340 MAE 0.6797
[P2.2] Ep 360 MAE 0.6786
[P2.2] Ep 380 MAE 0.6724
[P2.2] Ep 400 MAE 0.6696
[P2.2] Ep 420 MAE 0.6704
[P2.2] Ep 440 MAE 0.6697
[P2.2] Ep 460 MAE 0.6649
[P2.2] Ep 480 MAE 0.6629
[P2.2] Ep 500 MAE 0.6598

>>> Final Test Evaluation
------------------------------------------------------------
Method: Soft Random (Ratio=0.8)
MAE: 0.6081
RMSE: 0.7795
MAPE: 44.0688
Acc_10: 26.7045
Acc_20: 49.4318
------------------------------------------------------------
